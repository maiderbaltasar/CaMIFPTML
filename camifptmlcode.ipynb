{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9526201,"sourceType":"datasetVersion","datasetId":5800885},{"sourceId":10038455,"sourceType":"datasetVersion","datasetId":6183483},{"sourceId":199088646,"sourceType":"kernelVersion"}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, roc_auc_score, roc_curve)\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2024-12-02T18:12:01.180779Z","iopub.execute_input":"2024-12-02T18:12:01.181227Z","iopub.status.idle":"2024-12-02T18:12:03.285936Z","shell.execute_reply.started":"2024-12-02T18:12:01.181188Z","shell.execute_reply":"2024-12-02T18:12:03.284726Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\nexcel_file = '/kaggle/input/paper03dataegs/Python EGS.xlsx'\ndf = pd.read_excel(excel_file)\n\n# Preview the data\nprint(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 0. SELECT MOST RELEVANT FEATURES","metadata":{}},{"cell_type":"code","source":"# Compute the correlation matrix\ncorrelation_matrix = df.corr()\n\n# Visualize the correlation matrix\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\nplt.title(\"Feature Correlation Matrix\", fontsize=16)\n\n# Save the figure in high quality\nsave_path = '/kaggle/working/correlation_matrix.png'\nplt.savefig(save_path, dpi=300, bbox_inches='tight') \n\n# Show the figure\nplt.show()\n\nprint(f\"Correlation matrix figure saved at: {save_path}\")\n\n# Set a correlation threshold\nthreshold = 0.97\n\n# Identify features with high correlation\ncorrelated_features = set()\nfor i in range(len(correlation_matrix.columns)):\n    for j in range(i):\n        if abs(correlation_matrix.iloc[i, j]) > threshold:\n            correlated_features.add(correlation_matrix.columns[i])\n\nprint(f\"Features to be removed due to high correlation: {correlated_features}\")\n\n# Drop highly correlated features\ndf = df.drop(columns=correlated_features)\n\nprint(f\"Remaining columns after correlation filter: {df.columns}\")\n\n# Preview the data\nprint(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the variance threshold\nvar_threshold = 0.01\n\n# Apply variance thresholding\nselector = VarianceThreshold(threshold=var_threshold)\ndf_high_variance = selector.fit_transform(df)\n\n# Get the remaining features\nselected_features = df.columns[selector.get_support()]\ndf = pd.DataFrame(df_high_variance, columns=selected_features)\n\nprint(f\"Remaining columns after variance filter: {df.columns}\")\n\n# Preview the data\nprint(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the features and the target\nX = df.drop(columns=['f(vij)obj'])\ny = df['f(vij)obj']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # 1. RANDOM FOREST","metadata":{}},{"cell_type":"code","source":"# Initialize the Random Forest model\nrf_model = RandomForestClassifier()\n\n# Train the model\nrf_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_rf = rf_model.predict(X_train)\ny_test_pred_rf = rf_model.predict(X_test)\n\n# Accuracy\ntrain_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\ntest_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n\nprint(f'Random Forest - Training Accuracy: {train_accuracy_rf:.2f}')\nprint(f'Random Forest - Test Accuracy: {test_accuracy_rf:.2f}')\nprint(\"Classification Report for Random Forest (Training Set):\")\nprint(classification_report(y_train, y_train_pred_rf))\nprint(\"Classification Report for Random Forest (Test Set):\")\nprint(classification_report(y_test, y_test_pred_rf))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**1.1 Add Randomized SearchCV**","metadata":{}},{"cell_type":"code","source":"# Define the hyperparameter grid\nparam_distributions = {\n    'n_estimators': np.arange(10, 50, 100),\n    'max_depth': [None, 10, 20, 30, 40, 50],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'bootstrap': [True, False]\n}\n\n# Define the hyperparameter grid\nparam_distributions = {\n    'n_estimators': np.arange(50, 201, 10),\n    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70],\n    'min_samples_split': [2, 3, 4, 5, 10],\n    'min_samples_leaf': [1, 2, 3, 4, 5, 10],\n    'bootstrap': [True, False]\n}\n\n# Set up RandomizedSearchCV\nrandom_search = RandomizedSearchCV(\n    estimator=rf_model,\n    param_distributions=param_distributions,\n    n_iter=30,  \n    cv=3,      \n    verbose=2,\n    random_state=7,\n    n_jobs=-1\n)\n\n# Fit RandomizedSearchCV on the training data\nrandom_search.fit(X_train, y_train)\n\n# Get the best parameters from RandomizedSearchCV\nbest_params_random = random_search.best_params_\nprint(\"Best parameters from Randomized Search:\", best_params_random)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**1.2 Add GridSearchCV**","metadata":{}},{"cell_type":"code","source":"# Ensure we don't have invalid n_estimators\nn_estimators_values = [\n    max(1, best_params_random['n_estimators'] - 10),  \n    best_params_random['n_estimators'],\n    best_params_random['n_estimators'] + 10\n]\n\n# Create the parameter grid\nparam_grid = {\n    'n_estimators': n_estimators_values,\n    'max_depth': [best_params_random['max_depth'] - 5, best_params_random['max_depth'], best_params_random['max_depth'] + 5],\n    'min_samples_split': [best_params_random['min_samples_split'] - 1, best_params_random['min_samples_split'], best_params_random['min_samples_split'] + 1],\n    'min_samples_leaf': [best_params_random['min_samples_leaf'] - 1, best_params_random['min_samples_leaf'], best_params_random['min_samples_leaf'] + 1],\n    'bootstrap': [best_params_random['bootstrap']]\n}\n\n# Proceed with GridSearchCV setup and fitting\ngrid_search = GridSearchCV(\n    estimator=rf_model,\n    param_grid=param_grid,\n    cv=3,\n    verbose=2,\n    n_jobs=-1\n)\n\n# Fit GridSearchCV on the training data\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters from GridSearchCV\nbest_params_grid = grid_search.best_params_\nprint(\"Best parameters from Grid Search:\", best_params_grid)\n\n# Predict using the best model\nbest_rf_model = grid_search.best_estimator_\ny_test_pred = best_rf_model.predict(X_test)\n\n# Evaluate the model performance\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(f'Test Set Accuracy with Best Hyperparameters from Grid Search: {test_accuracy * 100:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**1.3 Evaluate the model**","metadata":{}},{"cell_type":"code","source":"# Get the best model from Grid Search\nbest_rf_model = grid_search.best_estimator_\n\n# Predictions on the training set\ny_train_pred = best_rf_model.predict(X_train)\n\n# Predictions on the test set\ny_test_pred = best_rf_model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Accuracy Score for the Training Set\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\nprint(f'Train Set Accuracy: {train_accuracy * 100:.2f}%')\n\n# 2. Accuracy Score for the Test Set\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(f'Test Set Accuracy: {test_accuracy * 100:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. How many predictions were correct out of the total for both sets\ntrain_correct = sum(y_train_pred == y_train)\ntest_correct = sum(y_test_pred == y_test)\n\nprint(f'Training set: {train_correct} correct out of {len(y_train)}')\nprint(f'Test set: {test_correct} correct out of {len(y_test)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Classification Report for the Training Set\nprint(\"Classification Report on Training Set:\")\nprint(classification_report(y_train, y_train_pred, digits=4))\n\n# 5. Classification Report for the Test Set\nprint(\"Classification Report on Test Set:\")\nprint(classification_report(y_test, y_test_pred, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Confusion Matrix for the Training Set\nprint(\"Confusion Matrix on Training Set:\")\nprint(confusion_matrix(y_train, y_train_pred))\n\n# 7. Confusion Matrix for the Test Set\nprint(\"Confusion Matrix on Test Set:\")\nprint(confusion_matrix(y_test, y_test_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to plot confusion matrix with percentages\ndef plot_confusion_matrix_with_percentages(y_true, y_pred, title, filename):\n    # Generate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Calculate percentages\n    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n\n    # Plot confusion matrix\n    plt.figure(figsize=(4, 3))\n    sns.heatmap(cm_percentage, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False)\n\n    # Add titles and labels\n    plt.title(f'{title} CM (%)', fontsize=11)\n    plt.xlabel('Predicted', fontsize=10)\n    plt.ylabel('Expected', fontsize=10)\n\n    # Adjust layout to prevent cropping\n    plt.tight_layout()\n\n    # Save the figure in high resolution (300 DPI)\n    plt.savefig(f'/kaggle/working/3{filename}.png', dpi=300) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check unique values in the training and test target variables for Random Forest\nunique_classes_rf = np.unique(y_train)\nprint(\"Unique classes in training set (RF):\", unique_classes_rf)\nunique_classes_test_rf = np.unique(y_test)\nprint(\"Unique classes in test set (RF):\", unique_classes_test_rf)\n\n# Plot and save confusion matrices for RF\nplot_confusion_matrix_with_percentages(y_train, y_train_pred, title=\"Training Set (RF)\", filename=\"RF_Train_Confusion_Matrix\")\nplot_confusion_matrix_with_percentages(y_test, y_test_pred, title=\"Test Set (RF)\", filename=\"RF_Test_Confusion_Matrix\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get feature importances from the best model\nfeature_importances = best_rf_model.feature_importances_\n\n# Create a DataFrame to hold feature names and their importances\nfeatures_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': feature_importances\n})\n\n# Sort the DataFrame by importance\nfeatures_df = features_df.sort_values(by='Importance', ascending=False)\n\n# Select the top 20 features\ntop_20_features = features_df.head(20)\n\n# Plot the top 20 feature importances\nplt.figure(figsize=(6, 4))\nplt.barh(top_20_features['Feature'], top_20_features['Importance'], color='skyblue')\nplt.xlabel('Importance', fontsize=14)\nplt.title('Top 20 Feature Importances (RF)', fontsize=16)\nplt.gca().invert_yaxis()  \n\n# Save the plot\nplt.tight_layout() \nplt.savefig('/kaggle/working/Top_20_Feature_Importances_RF.png', dpi=300)  \n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Support Vector Machine (SVM)","metadata":{}},{"cell_type":"code","source":"# Initialize the Support Vector Machine model\nsvm_model = SVC()\n\n# Train the model\nsvm_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_svm = svm_model.predict(X_train)\ny_test_pred_svm = svm_model.predict(X_test)\n\n# Accuracy\ntrain_accuracy_svm = accuracy_score(y_train, y_train_pred_svm)\ntest_accuracy_svm = accuracy_score(y_test, y_test_pred_svm)\n\nprint(f'Support Vector Machine - Training Accuracy: {train_accuracy_svm:.2f}')\nprint(f'Support Vector Machine - Test Accuracy: {test_accuracy_svm:.2f}')\nprint(\"Classification Report for SVM (Training Set):\")\nprint(classification_report(y_train, y_train_pred_svm))\nprint(\"Classification Report for SVM (Test Set):\")\nprint(classification_report(y_test, y_test_pred_svm))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"# Initialize the Decision Tree Classifier model\ndt_model = DecisionTreeClassifier()\n\n# Train the model\ndt_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_dt = dt_model.predict(X_train)\ny_test_pred_dt = dt_model.predict(X_test)\n\n# Accuracy\ntrain_accuracy_dt = accuracy_score(y_train, y_train_pred_dt)\ntest_accuracy_dt = accuracy_score(y_test, y_test_pred_dt)\n\nprint(f'Decision Tree - Training Accuracy: {train_accuracy_dt:.2f}')\nprint(f'Decision Tree - Test Accuracy: {test_accuracy_dt:.2f}')\nprint(\"Classification Report for Decision Tree (Training Set):\")\nprint(classification_report(y_train, y_train_pred_dt))\nprint(\"Classification Report for Decision Tree (Test Set):\")\nprint(classification_report(y_test, y_test_pred_dt))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. K-Nearest Neighbours KNN","metadata":{}},{"cell_type":"code","source":"# Initialize the KNN model\nknn_model = KNeighborsClassifier(n_neighbors=5) \n\n# Train the model\nknn_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_knn = knn_model.predict(X_train)\ny_test_pred_knn = knn_model.predict(X_test)\n\n# Accuracy\ntrain_accuracy_knn = accuracy_score(y_train, y_train_pred_knn)\ntest_accuracy_knn = accuracy_score(y_test, y_test_pred_knn)\n\nprint(f'K-Nearest Neighbors - Training Accuracy: {train_accuracy_knn:.2f}')\nprint(f'K-Nearest Neighbors - Test Accuracy: {test_accuracy_knn:.2f}')\nprint(\"Classification Report for KNN (Training Set):\")\nprint(classification_report(y_train, y_train_pred_knn))\nprint(\"Classification Report for KNN (Test Set):\")\nprint(classification_report(y_test, y_test_pred_knn))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"# Initialize the Gradient Boosting Classifier model\ngb_model = GradientBoostingClassifier()\n\n# Train the model\ngb_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_gb = gb_model.predict(X_train)\ny_test_pred_gb = gb_model.predict(X_test)\n\n# Accuracy\ntrain_accuracy_gb = accuracy_score(y_train, y_train_pred_gb)\ntest_accuracy_gb = accuracy_score(y_test, y_test_pred_gb)\n\nprint(f'Gradient Boosting Classifier - Training Accuracy: {train_accuracy_gb:.2f}')\nprint(f'Gradient Boosting Classifier - Test Accuracy: {test_accuracy_gb:.2f}')\nprint(\"Classification Report for Gradient Boosting (Training Set):\")\nprint(classification_report(y_train, y_train_pred_gb))\nprint(\"Classification Report for Gradient Boosting (Test Set):\")\nprint(classification_report(y_test, y_test_pred_gb))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. XGBoost","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model\nxgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Train the model\nxgb_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_xgb = xgb_model.predict(X_train)\ny_test_pred_xgb = xgb_model.predict(X_test)\n\n# Accuracy\ntrain_accuracy_xgb = accuracy_score(y_train, y_train_pred_xgb)\ntest_accuracy_xgb = accuracy_score(y_test, y_test_pred_xgb)\n\nprint(f'XGBoost - Training Accuracy: {train_accuracy_xgb:.2f}')\nprint(f'XGBoost - Test Accuracy: {test_accuracy_xgb:.2f}')\nprint(\"Classification Report for XGBoost (Training Set):\")\nprint(classification_report(y_train, y_train_pred_xgb))\nprint(\"Classification Report for XGBoost (Test Set):\")\nprint(classification_report(y_test, y_test_pred_xgb))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**6.1 Add Randomized SearchCV**","metadata":{}},{"cell_type":"code","source":"# Define the hyperparameter grid\nparam_distributions_xgb = {\n    'n_estimators': np.arange(50, 201, 10),\n    'max_depth': [3, 6, 10, 15],\n    'learning_rate': np.linspace(0.01, 0.3, 10),\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'gamma': [0, 0.1, 0.2, 0.3],\n    'min_child_weight': [1, 5, 10]\n}\n\n# Set up RandomizedSearchCV\nrandom_search_xgb = RandomizedSearchCV(\n    estimator=xgb_model,\n    param_distributions=param_distributions_xgb,\n    n_iter=30,  \n    cv=3,      \n    verbose=2,\n    random_state=7,\n    n_jobs=-1\n)\n\n# Fit RandomizedSearchCV on the training data\nrandom_search_xgb.fit(X_train, y_train)\n\n# Get the best parameters from RandomizedSearchCV\nbest_params_random_xgb = random_search_xgb.best_params_\nprint(\"Best parameters from Randomized Search for XGBoost:\", best_params_random_xgb)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**6.2 Add GridSearchCV**","metadata":{}},{"cell_type":"code","source":"# Ensure we don't have invalid n_estimators\nn_estimators_values_xgb = [\n    max(1, best_params_random_xgb['n_estimators'] - 10),\n    best_params_random_xgb['n_estimators'],\n    best_params_random_xgb['n_estimators'] + 10\n]\n\n# Create the parameter grid\nparam_grid_xgb = {\n    'n_estimators': n_estimators_values_xgb,\n    'max_depth': [best_params_random_xgb['max_depth'] - 2, best_params_random_xgb['max_depth'], best_params_random_xgb['max_depth'] + 2],\n    'learning_rate': [best_params_random_xgb['learning_rate'] - 0.05, best_params_random_xgb['learning_rate'], best_params_random_xgb['learning_rate'] + 0.05],\n    'subsample': [best_params_random_xgb['subsample']],\n    'colsample_bytree': [best_params_random_xgb['colsample_bytree']],\n    'gamma': [best_params_random_xgb['gamma']],\n    'min_child_weight': [best_params_random_xgb['min_child_weight']]\n}\n\n# Set up GridSearchCV\ngrid_search_xgb = GridSearchCV(\n    estimator=xgb_model,\n    param_grid=param_grid_xgb,\n    cv=3,\n    verbose=2,\n    n_jobs=-1\n)\n\n# Fit GridSearchCV on the training data\ngrid_search_xgb.fit(X_train, y_train)\n\n# Get the best parameters from GridSearchCV\nbest_params_grid_xgb = grid_search_xgb.best_params_\nprint(\"Best parameters from Grid Search for XGBoost:\", best_params_grid_xgb)\n\n# Predict using the best model\nbest_xgb_model = grid_search_xgb.best_estimator_\ny_test_pred_xgb = best_xgb_model.predict(X_test)\n\n# Evaluate the model performance\ntest_accuracy_xgb = accuracy_score(y_test, y_test_pred_xgb)\nprint(f'Test Set Accuracy with Best Hyperparameters from Grid Search: {test_accuracy_xgb * 100:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**6.3 Evaluate the model**","metadata":{}},{"cell_type":"code","source":"# Get the best model from Grid Search\nbest_xgb_model = grid_search_xgb.best_estimator_\n\n# Predictions on the training set\ny_train_pred_xgb = best_xgb_model.predict(X_train)\n\n# Predictions on the test set\ny_test_pred_xgb = best_xgb_model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Accuracy Score for the Training Set\ntrain_accuracy_xgb = accuracy_score(y_train, y_train_pred_xgb)\nprint(f'Train Set Accuracy: {train_accuracy_xgb * 100:.2f}%')\n\n# 2. Accuracy Score for the Test Set\ntest_accuracy_xgb = accuracy_score(y_test, y_test_pred_xgb)\nprint(f'Test Set Accuracy: {test_accuracy_xgb * 100:.2f}%')\n\n# 3. How many predictions were correct out of the total for both sets\ntrain_correct_xgb = sum(y_train_pred_xgb == y_train)\ntest_correct_xgb = sum(y_test_pred_xgb == y_test)\n\nprint(f'Training set: {train_correct_xgb} correct out of {len(y_train)}')\nprint(f'Test set: {test_correct_xgb} correct out of {len(y_test)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Classification Report for the Training Set\nprint(\"Classification Report on Training Set:\")\nprint(classification_report(y_train, y_train_pred_xgb, digits=4))\n\n# 5. Classification Report for the Test Set\nprint(\"Classification Report on Test Set:\")\nprint(classification_report(y_test, y_test_pred_xgb, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Confusion Matrix for the Training Set\nprint(\"Confusion Matrix on Training Set:\")\nprint(confusion_matrix(y_train, y_train_pred_xgb))\n\n# 7. Confusion Matrix for the Test Set\nprint(\"Confusion Matrix on Test Set:\")\nprint(confusion_matrix(y_test, y_test_pred_xgb))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check unique values in the training and test target variables for XGBoost\nunique_classes_xgb = np.unique(y_train)\nprint(\"Unique classes in training set (XGB):\", unique_classes_xgb)\nunique_classes_test_xgb = np.unique(y_test)\nprint(\"Unique classes in test set (XGB):\", unique_classes_test_xgb)\n\n# Plot and save confusion matrices for XGB\nplot_confusion_matrix_with_percentages(y_train, y_train_pred_xgb, title=\"Training Set (XGB)\", filename=\"XGB_Train_Confusion_Matrix\")\nplot_confusion_matrix_with_percentages(y_test, y_test_pred_xgb, title=\"Test Set (XGB)\", filename=\"XGB_Test_Confusion_Matrix\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get feature importances from the best model\nfeature_importances_xgb = best_xgb_model.feature_importances_\n\n# Create a DataFrame to hold feature names and their importances\nfeatures_df_xgb = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': feature_importances_xgb\n})\n\n# Sort the DataFrame by importance\nfeatures_df_xgb = features_df_xgb.sort_values(by='Importance', ascending=False)\n\n# Select the top 20 features\ntop_20_features_xgb = features_df_xgb.head(12)\n\n# Plot the top 20 feature importances\nplt.figure(figsize=(5, 3))\nplt.barh(top_20_features_xgb['Feature'], top_20_features_xgb['Importance'], color='skyblue')\nplt.xlabel('Importance', fontsize=10)\nplt.title('Top 20 Feature Importances (XGB)', fontsize=10)\nplt.gca().invert_yaxis()  \nplt.yticks(fontsize=8)  \nplt.xticks(fontsize=8) \n\n# Save the plot\nplt.tight_layout()  \nplt.savefig('/kaggle/working/Top_20_Feature_Importances_XGB.png', dpi=300)  \n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Model Comparison","metadata":{}},{"cell_type":"code","source":"# Initialize model results dictionary\nmodel_results = {}\n\n# Define the models\nmodels = {\n    'Random Forest': RandomForestClassifier(),\n    'Support Vector Machine': SVC(probability=True),\n    'Decision Tree': DecisionTreeClassifier(),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n}\n\n# Train and evaluate each model\nfor model_name, model in models.items():\n    print(f'Training {model_name}...')\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    # Accuracy\n    train_accuracy = accuracy_score(y_train, y_train_pred)\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    \n    # AUROC for Test Data\n    y_test_proba = model.predict_proba(X_test)[:, 1]  \n    test_roc_auc = roc_auc_score(y_test, y_test_proba)\n    \n    # AUROC for Train Data\n    y_train_proba = model.predict_proba(X_train)[:, 1] \n    train_roc_auc = roc_auc_score(y_train, y_train_proba)\n    \n    # Save results\n    model_results[model_name] = {\n        'Train Accuracy': train_accuracy,\n        'Test Accuracy': test_accuracy,\n        'Train ROC AUC': train_roc_auc,\n        'Test ROC AUC': test_roc_auc\n    }\n\n    print(f'{model_name} - Train Accuracy: {train_accuracy:.2f}, Test Accuracy: {test_accuracy:.2f}, Train ROC AUC: {train_roc_auc:.2f}, Test ROC AUC: {test_roc_auc:.2f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**7.1 Bar Plot**","metadata":{}},{"cell_type":"code","source":"# Convert the results dictionary into a DataFrame\nresults_df = pd.DataFrame(model_results).T  \nresults_df.reset_index(inplace=True)\nresults_df.rename(columns={'index': 'Model'}, inplace=True)\n\n# Sort the DataFrame by 'Test Accuracy'\nresults_df.sort_values(by='Test Accuracy', ascending=False, inplace=True)\n\n# Convert accuracies to percentages\nresults_df['Train Accuracy'] *= 100\nresults_df['Test Accuracy'] *= 100\n\n# Melt the DataFrame to long format for plotting both train and test accuracy\nresults_melted = results_df.melt(id_vars='Model', value_vars=['Train Accuracy', 'Test Accuracy'], \n                                 var_name='Accuracy Type', value_name='Accuracy')\n\n# Plot the combined accuracy plot with vibrant colors\nplt.figure(figsize=(12, 8)) \nax = sns.barplot(x='Accuracy', y='Model', hue='Accuracy Type', data=results_melted, palette='magma')\n\n# Add title and labels with larger font sizes\nplt.title('Model Train vs Test Accuracy Comparison', fontsize=20)\nplt.xlabel('Accuracy (%)', fontsize=18)\nplt.ylabel('Model', fontsize=18)\n\n# Customize tick parameters for both axes\nax.tick_params(axis='x', labelsize=14)  \nax.tick_params(axis='y', labelsize=14)  \n\n# Position legend outside the plot\nlegend = ax.legend(title='Accuracy Type', fontsize=14, title_fontsize=16, loc='upper center', \n                   bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)  \n\n# Add percentage values on the bars with larger font size\nfor container in ax.containers:\n    ax.bar_label(container, fmt='%.1f%%', label_type='edge', fontsize=14, padding=5)\n\n# Adjust layout\nplt.tight_layout()\n\n# Save the plot\nsave_path = '/kaggle/working/model_accuracy_comparison.png'\nplt.savefig(save_path, dpi=300) \nplt.show()\n\nprint(f\"Plot saved at {save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**7.2 Plot ROC Curves for All Models**","metadata":{}},{"cell_type":"code","source":"# Create a figure\nplt.figure(figsize=(8, 6))\n\n# Plot ROC curves for each model\nfor model_name, model in models.items():\n    # Predict probabilities\n    y_test_proba = model.predict_proba(X_test)[:, 1]\n    \n    # ROC curve\n    fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n    \n    # Plot ROC curve\n    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {model_results[model_name][\"Test ROC AUC\"]:.2f})')\n\n# Add diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\n\n# Add labels, title, and legend\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curves Comparison (Test)', fontsize=14)\nplt.legend(loc='lower right')\n\n# Save the figure\nsave_path = '/kaggle/working/roc_curves_comparison.png'\nplt.savefig(save_path, dpi=300)\n\n# Show the figure\nplt.show()\n\nprint(f\"ROC curve figure saved at: {save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a figure\nplt.figure(figsize=(8, 6))\n\n# Plot ROC curves for each model using training data\nfor model_name, model in models.items():\n    # Predict probabilities\n    y_train_proba = model.predict_proba(X_train)[:, 1]\n    \n    # ROC curve\n    fpr, tpr, _ = roc_curve(y_train, y_train_proba)\n    \n    # Plot ROC curve\n    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {model_results[model_name][\"Train ROC AUC\"]:.2f})')\n\n# Add diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\n\n# Add labels, title, and legend\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)', fontsize=12)\nplt.ylabel('True Positive Rate (TPR)', fontsize=12)\nplt.title('ROC Curves Comparison (Training)', fontsize=14)\nplt.legend(loc='lower right')\n\n# Save the figure\nsave_path = '/kaggle/working/roc_curves_train_comparison.png'\nplt.savefig(save_path, dpi=300) \n\n# Show the figure\nplt.show()\n\nprint(f\"ROC curve figure saved at: {save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**7.3 Comparative Table**","metadata":{}},{"cell_type":"code","source":"# Create DataFrame from model_results\nresults_df = pd.DataFrame([\n    {\n        'Model': model_name,\n        'Train Accuracy': metrics['Train Accuracy'],\n        'Test Accuracy': metrics['Test Accuracy'],\n        'Train ROC AUC': metrics['Train ROC AUC'],  # Include Train ROC AUC\n        'Test ROC AUC': metrics['Test ROC AUC'],    # Include Test ROC AUC\n    }\n    for model_name, metrics in model_results.items()\n])\n\n# Print the final DataFrame with the desired columns\nprint(results_df[['Model', 'Train Accuracy', 'Test Accuracy', 'Train ROC AUC', 'Test ROC AUC']].to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}